# Crowd-activity-analysis

crowd activity recognition using Transformer

We used Transformer to extract temporal and spatial features, and then completed crowd activity recognition through these features. The interesting work is to introduce salient idea into feature extraction process.

Dataset: Collective Activity Dataset
The dataset consists of 44 video sequences, including 32 for training and 12 for testing, totaling 25,907 frames, ranging from 151 to 1813 frames per sequence. There are 44 files in the dataset, each representing a video sequence. Each file contains a label file named "annotation.txt" and all the frames of the respective video sequence. The label file includes multiple lines of information, with each line containing individual bounding boxes, individual action labels, and crowd activity labels. The dataset contains five different collective activities: crossing, waiting, queuing, walking, and talking.
https://cvgl.stanford.edu/projects/collective/collectiveActivity.html

The code will come soon.
